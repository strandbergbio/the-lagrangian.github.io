---
layout: post
title: 
date: '2016-05-28T13:48:00.000-04:00'
author: Adam Strandberg
tags: 
modified_time: '2016-05-28T13:48:28.866-04:00'
blogger_id: tag:blogger.com,1999:blog-1900836931245934345.post-2815514402979550522
blogger_orig_url: https://www.blogger.com/comment.g?blogID=1900836931245934345&postID=2815514402979550522&isPopup=true
---

<div>If you've been on the internet for the past couple of months, you've probably seen some pictures from Google's Deep Dream neural network.<br /><br />I don't think anyone's done a formal study on the issue, but it's no secret Deep Dream's images look like<br />How can a program generate this uncomfortable, turbulent collision of liquified abstractions?<br /><br /><br /><br />Now we have a system that can take data and produce a concept, but also take a concept and produce data. Obviously, we should turn it into an <a href="https://en.wikipedia.org/wiki/Ouroboros">ouroboros</a> by feeding it to itself. The network is fed an image. It classifies some component of the image and then amplifies what it sees. It looks at it again and re-edits, again amplifying each component.<br /><br />In the video below, the image starts as completely random noise. Each frame is recursively fed back into a particular network layer, starting with the topmost one. Every 4 seconds the cycle shifts another layer deeper in the network nodes. Although the edge patterns at the beginning are interesting, it doesn't really start diving off the deep end until around 1:30. Beware the tunnel of dog-lizard eyes.</div><div><br /></div><div><br /></div><iframe allowfullscreen="" frameborder="0" height="281" mozallowfullscreen="" src="https://player.vimeo.com/video/132700334?color=ffffff" webkitallowfullscreen="" width="500"></iframe> <br /><a href="https://vimeo.com/132700334">Inside an artificial brain</a> from <a href="https://vimeo.com/jncx">Johan Nordberg</a> on <a href="https://vimeo.com/">Vimeo</a>.<br /><div><br /></div><div><br /></div><div><br /><br />One of the nice things about these loops is that they can decrease the need for cumbersome detailed representations of the world that are either computationally costly or impossible.<br />In the real world you don't need to be able to model the whole world based on some fixed set of information. You just need to know where to look next to get the information you need. (See my post on <a href="http://the-lagrangian.blogspot.com/2014/12/pointer-y-cognition.html">pointer-y cognition</a>&nbsp;for more.)<br /><br /><br /></div><div><br /></div><div><br /></div><div><br /></div><div><br /></div><div>“An important thing to remember is that all normal sensory perception in humans is hallucinations constrained by sensory input,” said Lucas Sjulson, a research assistant professor at New York University’s Langone Neuroscience Institute. “So our hallucinations correspond to some degree to what's actually in the outside world. But perceptions are all internally generated.” </div><br />